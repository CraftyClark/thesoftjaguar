<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>reveal.js - The HTML Presentation Framework</title>

        <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
        <meta name="author" content="Hakim El Hattab">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
        <link rel="stylesheet" href="http://thesoftjaguar.com/theme/reveal/css/reveal.min.css">
        <link rel="stylesheet" href="http://thesoftjaguar.com/theme/reveal/css/theme/default.css" id="theme">

        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="http://thesoftjaguar.com/theme/reveal/lib/css/beige.css">

        <!-- If the query includes 'print-pdf', use the PDF print sheet -->
        <script>
            document.write( '<link rel="stylesheet" href="http://thesoftjaguar.com/theme/css/reveal/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
        </script>

        <!--[if lt IE 9]>
        <script src="http://thesoftjaguar.com/theme/lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">
                
                <section data-markdown>
                    <script type="text/template">
                        

# Python WSGI servers

### The pros and cons of different deployment strategies



June 2013 - Darío Blanco  

dario.blanco@edelight.de






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Best practices



* Control daemons remotely with `supervisord`

* Manage your python environment with `virtualenv`

* Install python packages with `pip`

* Deploy your application stack with `Chef` or `Puppet`

* Automate some tasks with `fabric`






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## How can I serve my python webapp?



### WSGI



**Universal interface** between **web servers** and **Python** web applications or frameworks.

Frameworks like **Django** or **Flask** are WSGI applications.

Web servers should support the **WSGI protocol** (as a module or natively).

![WSGI](http://i.imgur.com/grlvXUA.png)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## How can I serve my python webapp?



* Web servers written in Python

* Web servers embedding Python






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Non-Python-based web servers

We may want static files, proxying, security (SSL/TLS, LDAP...), virtual hosts, load balancing, url rewrite, compression...

* `Apache`

 * **Multi threaded** architecture

* `Nginx`

 * Event driven **single threaded** architecture






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache MPM module

* `Apache` launches **child processes**, forking and killing in base of the demand

* Better than the **prefork model** (thread per request instead of process per request)

* **Worker pool** reduces overhead when starting and destroying processes 

 * Still **context switches** between threads in one CPU






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache MPM module

``` bash

    ServerLimit 16  # Max number of child processes

    StartServers 2  # Child processes when Apache starts

    MaxClients 150  # Maximum overall number of threads

    MinSpareThreads 25  # Minimum overall number of idle threads

    MaxSpareThreads 75  # Maximum overall number of idle threads

    ThreadsPerChild 25  # Fixed threads per child process

    MaxRequestsPerChild  4000  # Process recycling (old ones)

```

`ThreadsPerChild`

* **Server** threads (blocked on I/O)

* **Idle** threads (consuming resources anyway)




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache MPM module

![Apache MPM overview](http://i.imgur.com/LU82F2l.png)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx Core module

* One **master process** starts and monitors **worker processes** that handle connections

 * Less **RAM** consumption

 * Better **CPU** use: no **context switches** between threads

* **Event driven** workers






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx Core module

* Uses an **event loop**: `epoll`, `kqueue`, `select`

``` bash

    worker_processes  1;

    events {

        worker_connections  1024;  # Use file descriptors (sockets)

        use epoll;

    }

```

* A small number of **workers** can serve a lot of requests

* Attaches a **callback** to the request and works on another active client




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx Event Loop

![Nginx Event Loop overview](http://i.imgur.com/SEObv0n.png)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx Event Loop

![Science](http://i.imgur.com/pRDiiOZ.png)




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Maximum number of clients in Nginx

`Nginx` uses **file descriptors** from the same **pool** 

``` bash

    max clients = worker_processes * worker_connections

```  



A **browser** usually opens 2 persistent connections by default (HTTP 1.1)...

``` bash

    max clients = worker_processes * worker_connections/2

```  



And as a **reverse proxy**, it uses an extra connection to the backend

``` bash

    max clients = worker_processes * worker_connections/4

```




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## The Reverse Proxy dilemma

Embed `python` (`mod_wsgi` or `NgxWSGIModule`) or just act as a **reverse proxy** to other `python` web server?  

![Reverse Proxy](http://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Reverse_proxy_h2g2bob.svg/400px-Reverse_proxy_h2g2bob.svg.png)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## The Reverse Proxy dilemma



Running `python` in a separate process:

* **Web server** handles only **static content** in tiny threads

* Each `python` process run its own **interpreter**

* **Static** and **backend** servers can be in different instances






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Some famous Python WSGI servers



Aspen, **Apache + mod_wsgi**, CherryPy, Cogen, Concurrence, Eventlet, FAPWS3, **GEvent**, **Gunicorn** , httpy, Magnum Py, Medusa, Apache + ModPython, **Nginx + NgxWSGIModule**, Rocket, Spawning, **uWSGI**, **Tornado**, **Twisted**, Waitress, ...  






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Oh God! There are many!

### We can't try them all, that's crazy

![Web servers](http://i.imgur.com/QYD1ZxR.png)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Let's select some



* Apache + mod_wsgi

* GEvent

* Gunicorn

* Nginx + NgxWSGIModule

* uWSGI

* Tornado






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Why?



* We are familiar with them

* Seem to solve our **performance** problems

* Promising **benchmarks**

* Maturity

* Recommended by python **web frameworks**

* Simplicity






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache mod_wsgi



* Very **easy** to deploy

* Reasonably **fast** and **stable**

* Almost a **standard** on the web

* **LDAP** support in `debian squeeze`

* C10K problem

* Forget about being **asynchronous**






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## gevent



* **Asynchronous** power

 * `libev`

 * `greenlet`

* We want the asynchronous feature as something optional

* Monkey patching

* **Version** problem:

 * Release candidate: 1.0 (required by uWSGI)

 * Pip package: 0.13.8

 * Wheezy package: 0.13.6






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Gunicorn



* **"Complex"** deployment

  * `Nginx`

  * `supervisord`

* Can plug in `gevent`

* Different types of workers

  * Synchronous

  * Asynchronous

  * Tornado

* `total_workers = (2 x $num_cores) + 1`






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx + NgxWSGIModule



* No **LDAP** support in `debian squeeze` (added in `wheezy`)

* **LDAP** support in `wheezy` (`auth-pam` module)

* Apache's `mod_wsgi` copy

* Forget about being asynchronous (even if `Nginx` is), but...

 * Future WSGI extensions for asynchronous programming






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Tornado



* We already use it, and we are quite happy

* You "have to" go **asynchronous** to take advantage of all of its power

* It is also a **framework**

* **REFACTOR** your code






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## uWSGI



* The **benchmarks** are really promising

* `Nginx` + `uWSGI` + `Flask` is a very famous and well documented stack

* **Flexible**

  * `Apache`, `Cherokee`, `Lighttpd`, `Mongrel2` or `Nginx` in front

  * Standalone HTTP/HTTPS Server






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## uWSGI



* Components

  * **Core**

  * **Request plugins** (WSGI, PSGI, Rack, Lua WSAPI, CGI, PHP, Go ...)

  * **Gateways** (load balancers, proxies and routers)

  * **Emperor** (management and monitoring of multiple instances)

  * **Loop engines** (uGreen, Greenlet, Stackless, Gevent, Goroutines and Fibers)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## The Final Step

* **Web servers**  

  * `Apache` + `mod_wsgi`

  * `Nginx` + `uWSGI`

* **Web framework**  

  * `Flask` (*WalterWhiteWeb*)






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## WalterWhiteWeb



* `/` route

* Sorts a **tuple list** of 98 chemical elements from the periodic table in alphabetic order

* Chooses an element **randomly**

* Renders the template with that element and a 94 KB image






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## WalterWhiteWeb

``` python

PERIODIC_ELEMENTS = [

    ("Hydrogen", "H"),

    ("Fermium", "Fm"),

    ...

]  # 98 elements



@app.route('/')

def index():

    elements = sorted(PERIODIC_ELEMENTS)

    element = choice(elements)

    db.elements.find_one({'_id': element[1]})

    return render_template('index.html', element=element)

```




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## WalterWhiteWeb

![WalterWhiteWeb](http://i.imgur.com/fW9USC8.png)

[walterwhiteweb.darioblanco.com](http://walterwhiteweb.darioblanco.com)




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache + mod_wsgi deployment

`Apache` configuration file

``` apache

  <VirtualHost *>

    ServerName walterwhiteweb.com

    WSGIDaemonProcess walterwhiteweb user=user1 group=group1 threads=5

    WSGIScriptAlias / /myprojecs/walterwhiteweb/walterwhiteweb.wsgi

    <Directory /myprojecs/walterwhiteweb>

      WSGIProcessGroup walterwhiteweb

      WSGIApplicationGroup %{GLOBAL}

      Order deny,allow

      Allow from all

    </Directory>

  </VirtualHost>

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Apache + mod_wsgi deployment

`wsgi` file (it supports `virtualenv`)

``` python

    import sys

    sys.path.append('/myprojects/walterwhiteweb')

    from walterwhiteweb import app as application

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx + uWSGI deployment



`Nginx` configuration file

``` nginx

    location / { try_files $uri @walterwhiteweb; }

    location @walterwhiteweb {

        include uwsgi_params;

        uwsgi_pass unix:/tmp/uwsgi.sock;

    }

```

Execute the backend `uWSGI` server

``` bash

    $ uwsgi -s /tmp/uwsgi.sock -w walterwhiteweb:app

```




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        



## Nginx + uWSGI deployment

Or use a `uwsgiconfig.ini` file when running uWSGI

``` bash

    [uwsgi]

    chdir = /myprojects/walterwhiteweb

    processes = 4

    threads = 2

    stats = 127.0.0.1:9191

    module = walterwhiteweb

    callable = app

    master = true

    socket = /tmp/uwsgi.sock  # When using with nginx

    # http = 0.0.0.0:80  # Standalone mode

    # gevent = 2000  # Asynchronous cores for gevent

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Nginx + uWSGI deployment



And then run our little baby

``` bash

    $ uwsgi uwsgiconfig.ini

```

or

``` bash

    $ sudo service uwsgi start

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Differences with Nginx + Gunicorn

`Nginx` configuration file

``` nginx

    location / {

        proxy_pass_header Server;

        proxy_set_header Host $http_host;

        proxy_redirect off;

        proxy_set_header X-Real-IP $remote_addr;

        proxy_set_header X-Scheme $scheme;

        proxy_connect_timeout 10;

        proxy_read_timeout 10;

        proxy_pass http://127.0.0.1:8000;

    }

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Differences with Nginx + Gunicorn



`Gunicorn` configuration file

``` bash

    user = 'www-data'

    group = 'www-data'

    bind = '127.0.0.1:8000'

    workers = 4

    accesslog = '/var/log/walterwhiteweb.access.log'

    errorlog = '/var/log/walterwhiteweb.error.log'

    loglevel = 'info'

    pythonpath = '/myprojects/walterwhiteweb'

    debug = False

```




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Benchmark tool

* `requests` python library

* `gevent` and `Greenlet` for managing **concurrent connections**

* Statistics

 * **Timeout** rate

 * **Fastest request** time

 * **Slowest request** time

 * **Total** mean time






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Benchmark configuration

* 1000 requests sent

* Different grade of concurrency (from 1 to 100)

``` bash

    $ python webservbench.py -e http://walterwhiteweb.darioblanco.com

    -n 1000 -c 100

```






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## The Endpoint

* `debian wheezy`

* 5 GB Ram

* 2 CPUs






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## The Server set-up

* `Apache` 2.2.22-13 default settings

 * 2 starting child processes with 25 threads each

* `Nginx` 1.2.1-2.2 default settings

 * 4 workers, 768 connections

* `uWSGI` 1.2.3

 * 1 process, 5 threads






                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Benchmark results

![Results](http://i.imgur.com/hPIODHv.png)




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## uWSGI improvements

With **50** concurrent connections

* **1** process and **5** threads: **1055 ms**

* **2** processes and **25** threads: **401 ms**

There can be even more **improvements**

* `uWSGI` **cheaper subsystem**

* `uWSGI` **Emperor**

* **Broodlord** mode

* **Zerg** mode




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

## Conclusions

* `Apache + mod_wsgi` is the best choice in most of the cases

  * Easiest deployment

  * Things can get **ugly** with more concurrency

  * If you want to scale, it is not an **option**

* `Nginx + uWSGI` is a great **alternative**, not only for scaling

  * **Not difficult** to deploy

  * Astonishing **functionality** and **configuration** options

  * Modularity

  * You can be *true asynchronous*, but you don't have to




                    </script>
                </section>
                
                <section data-markdown>
                    <script type="text/template">
                        

### Darío Blanco

Some related projects in my [sharkerz@github](https://github.com/sharkerz) account

* [uwsgi_server](https://github.com/sharkerz/uwsgi_server)

* [creeper](https://github.com/sharkerz/creeper)




                    </script>
                </section>
                
            </div>

        </div>

        <script src="http://thesoftjaguar.com/theme/reveal/lib/js/head.min.js"></script>
        <script src="http://thesoftjaguar.com/theme/reveal/js/reveal.min.js"></script>

        <script>

            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: true,

                theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
                transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: 'http://thesoftjaguar.com/theme/reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'http://thesoftjaguar.com/theme/reveal/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'http://thesoftjaguar.com/theme/reveal/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'http://thesoftjaguar.com/theme/reveal/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'http://thesoftjaguar.com/theme/reveal/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'http://thesoftjaguar.com/theme/reveal/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'http://thesoftjaguar.com/theme/reveal/plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
                    // { src: 'http://thesoftjaguar.com/theme/reveal/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
                ]
            });

        </script>

    </body>
</html>