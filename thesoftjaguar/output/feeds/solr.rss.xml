<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>The soft jaguar</title><link>http://thesoftjaguar.com/</link><description></description><atom:link href="http://thesoftjaguar.com/feeds/solr.rss.xml" rel="self"></atom:link><lastBuildDate>Tue, 30 Jul 2013 09:51:00 +0200</lastBuildDate><item><title>Berlin Buzzwords 2013</title><link>http://thesoftjaguar.com/posts/2013/07/30/berlin-buzzwords-2013/</link><description>&lt;p&gt;&lt;em&gt;Berlin Buzzwords&lt;/em&gt; took place on June 3rd and 4th at &lt;a href="http://kulturbrauerei.de/en"&gt;Kulturbrauerei&lt;/a&gt;, which is an awesome place. &lt;em&gt;Buzzwords&lt;/em&gt; is a conference focused in Open Source technologies, mainly related to search engines, &lt;em&gt;Big Data&lt;/em&gt; and &lt;em&gt;NoSQL&lt;/em&gt; databases, having three main topics: &lt;code&gt;search&lt;/code&gt;, &lt;code&gt;store&lt;/code&gt; and &lt;code&gt;scale&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The main technologies from the talks that I attended were &lt;a href="http://www.elasticsearch.org/"&gt;Elasticsearch&lt;/a&gt;, &lt;a href="http://lucene.apache.org/solr/"&gt;Solr&lt;/a&gt; &lt;a href="http://cassandra.apache.org/"&gt;Cassandra&lt;/a&gt;, &lt;a href="http://hadoop.apache.org/"&gt;Hadoop&lt;/a&gt;, &lt;a href="http://pig.apache.org/"&gt;Pig&lt;/a&gt;, &lt;a href="http://mahout.apache.org/"&gt;Mahout&lt;/a&gt;, &lt;a href="http://fitnesse.org/"&gt;FitNesse&lt;/a&gt;, &lt;a href="http://www.mongodb.org/"&gt;MongoDB&lt;/a&gt;, &lt;a href="http://logstash.net/"&gt;Logstash&lt;/a&gt; and &lt;a href="http://kibana.org/"&gt;Kibana&lt;/a&gt;, among others.&lt;/p&gt;
&lt;p&gt;Instead of explaining what was going on in each talk that I attended, I have decided to cover the three main areas of the conference.&lt;/p&gt;
&lt;h1&gt;Search&lt;/h1&gt;
&lt;p&gt;This topic covers several search engines, mainly &lt;em&gt;Elasticsearch&lt;/em&gt;, but also &lt;em&gt;Solr&lt;/em&gt; (and of course &lt;em&gt;Lucene&lt;/em&gt; as the base), which are quite famous. But it also wraps how to analyze a lot of log information (or just a lot of data). I mainly attended &lt;em&gt;Elasticsearch&lt;/em&gt; talks, but there were more technologies involved.&lt;/p&gt;
&lt;h2&gt;Just search&lt;/h2&gt;
&lt;p&gt;So we want to get started with a search engine, but... How do we use them? &lt;a href="http://berlinbuzzwords.de/sessions/getting-down-and-dirty-elasticsearch"&gt;Getting down and dirty with Elasticsearch&lt;/a&gt; starts from the basic concepts and explains how to improve our queries (which, IMHO, is the most interesting part of this talk). It differences exact values search (should match &lt;strong&gt;entirely&lt;/strong&gt;) from full text search (search within the text), it introduces the &lt;em&gt;inverted index&lt;/em&gt; concept for improving full text search, which is being done separating words and terms, sorting unique terms and listing docs containing those terms, via the use of &lt;strong&gt;analyzers&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The exact matching is done (or should be done) with &lt;strong&gt;filters&lt;/strong&gt;, and the text search is achieved with &lt;strong&gt;queries&lt;/strong&gt;, so the filters are faster than the queries and cacheable, but the queries provide the full text search. Finally, the talk addresses some different ways of implementing &lt;strong&gt;autocomplete&lt;/strong&gt;: the &lt;em&gt;N-grams&lt;/em&gt; method, good for partial word matching, and the &lt;em&gt;Edge N-grams&lt;/em&gt; method, perfect for autocomplete (just activating the type &lt;code&gt;edge_ngram&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;analyzers&lt;/strong&gt; is a very interesting topic, helping us to deal with different languages at query time. &lt;a href="http://berlinbuzzwords.de/sessions/language-support-and-linguistics-lucenesolrelasticsearch-and-open-source-and-commercial-eco"&gt;Language Support and Linguistics in Lucene/Solr/Elasticsearch and the open source ecosystem&lt;/a&gt; explains again the tokenization and normalization of the given text query, where the tokens are mapped to the document ids that contain them.&lt;/p&gt;
&lt;p&gt;However, we will find the &lt;a href="http://en.wikipedia.org/wiki/Precision_and_recall"&gt;precision and recall&lt;/a&gt; problem. The talk explains how Lucene, Elasticsearch and Solr deals with this, and how the synonyms can improve the recall. About the latter, the best practice is to apply the synonyms in the query side instead of in the index: it allows synonym updating without reindexing and is easier to turn the synonym feature off.&lt;/p&gt;
&lt;p&gt;When we work with &lt;em&gt;NoSQL&lt;/em&gt; based solutions, in this case with Elasticsearch, we always have a problem: how to divide the relational data? &lt;a href="http://berlinbuzzwords.de/sessions/document-relations-elasticsearch"&gt;Document relations with Elasticsearch&lt;/a&gt; gives two answers to this problem. The first one is about setting the &lt;code&gt;_parent&lt;/code&gt; field in the desired mapping, for linking the current document (&lt;em&gt;child&lt;/em&gt;) to another one (&lt;em&gt;parent&lt;/em&gt;). The advantage is that the parent document doesn't need to exist at indexing time, which improves the performance, and if we want to have the parent documents based on matches with their child ones, we can always set the &lt;code&gt;has_child&lt;/code&gt; query.&lt;/p&gt;
&lt;p&gt;The second workaround is the use of &lt;strong&gt;nested objects&lt;/strong&gt;. We can set a JSON document with nested fields, instead of defining a parent, using the &lt;code&gt;nested&lt;/code&gt; field type (which triggers Lucene's &lt;em&gt;block indexing&lt;/em&gt;). This document will be flattened and the &lt;em&gt;block indexing&lt;/em&gt; translate the ES document into multiple Lucene documents. With this approach, the root document and its nested documents remain always in the same block, and when querying, you establish it as a nested query, specify the nested level, the score mode and then the query inside that nested document.&lt;/p&gt;
&lt;h2&gt;Test driven development in Big Data&lt;/h2&gt;
&lt;p&gt;The search topic is also closely related to Big Data. What's the point of having tons and tons of data if we can't find anything useful there? Big Data solutions usually are complex and not easy to test.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://berlinbuzzwords.de/sessions/bug-bites-elephant-test-driven-quality-assurance-big-data-application-development"&gt;Bug bites Elephant?&lt;/a&gt; presents a way of assuring quality data following the Test-driven development process, specifically when using &lt;em&gt;Hadoop&lt;/em&gt;, &lt;em&gt;Pig&lt;/em&gt; and/or &lt;em&gt;Hive&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There are several ways of achieving this (&lt;em&gt;JUnit&lt;/em&gt;, &lt;em&gt;MRUnit&lt;/em&gt;, &lt;em&gt;iTest&lt;/em&gt; or simply using scripts), but the talk introduces &lt;em&gt;FitNesse&lt;/em&gt; as a natural language test specification, where the tests are written as stories instead as programming code. The FitNesse server translates the natural language into Java and integrates with REST or Jenkins if needed.&lt;/p&gt;
&lt;p&gt;This has several advantages, like having a wiki page with the tests written in a language that everyone can understand (or integrate PigLatin directly into that wiki page). However, natural language has its limits, like for instance, if you want to check the expected result (like the output of a Pig job alias).&lt;/p&gt;
&lt;h2&gt;Don't drown in a log ocean&lt;/h2&gt;
&lt;p&gt;Who hasn't had issues when dealing with log information? We want to know what's going on when something is wrong, but sometimes the log is too verbose (Java :P) or simply we have the log files distributed among a lot of servers.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://berlinbuzzwords.de/sessions/state-open-source-logging"&gt;The State of Open Source Logging&lt;/a&gt; shows some technologies that address this problem, like &lt;em&gt;fluentd&lt;/em&gt;, &lt;em&gt;Logstash&lt;/em&gt;, &lt;em&gt;Graylog2&lt;/em&gt;, &lt;em&gt;ELSA&lt;/em&gt;, &lt;em&gt;Flume&lt;/em&gt; or &lt;em&gt;Scribe&lt;/em&gt;. Therefore, one work around to this problem is to centralize all log files into a Elasticsearch cluster, transforming every log line into a JSON document. The talk is focused on the &lt;strong&gt;Kibana&lt;/strong&gt; way, which is a very powerful Logstash and Elasticsearch interface.&lt;/p&gt;
&lt;h2&gt;Machine learning baby&lt;/h2&gt;
&lt;p&gt;Imagine that we have access to a lot of data, and actually we can (Twitter Public API). Now we want to do something useful with that data, like in &lt;a href="http://berlinbuzzwords.de/sessions/geospatial-event-detection-twitter-stream"&gt;Geospatial Event Detection in the Twitter Stream&lt;/a&gt;, a nice talk stating the desire of creating real actionable insights from tweet data: fires, police alerts, events, demonstrations, accidents...&lt;/p&gt;
&lt;p&gt;In order to detect those events, they grouped the tweets by location (tweet cluster) storing them in &lt;em&gt;MongoDB&lt;/em&gt;, and then, check if the tweets from the cluster belong to the same topic (marking the group as good). Where is the machine learning? Well, marking the tweet cluster as good is not a trivial thing: the use of a machine learning tool (like Weka) can solve the problem.&lt;/p&gt;
&lt;p&gt;The machine learning tool will then make a choice (is the cluster good or bad?) based on a series of user defined rules. In this specific case, it was checking if the tweets had a common theme (n-gram overlap), sentiment (was it positive, negative? Which was the overall sentiment? What would be the sentiment strenght?), subjectivity, number of hashtags, retweet ratio, event categories, embedded links, foursquare tweets (or other kind of predefined tweets), total number of tweets in the cluster, unique locations, bad locations (airports, train stations...), among other parameters. This highlights the relevance of having an important number of quality rules, besides the tool used for performing machine learning.&lt;/p&gt;
&lt;h1&gt;Store&lt;/h1&gt;
&lt;h2&gt;Cassandra in da house&lt;/h2&gt;
&lt;p&gt;I didn't assist a lot of &lt;code&gt;Store&lt;/code&gt; talks, and the ones that I did were almost all about &lt;em&gt;Cassandra&lt;/em&gt;, topic in which I am not too familiar with. &lt;a href="http://berlinbuzzwords.de/sessions/cassandras-evolutions"&gt;On Cassandra's Evolution&lt;/a&gt; gave a brief explanation about Casandra's ring of nodes.&lt;/p&gt;
&lt;p&gt;They explain the concept of &lt;em&gt;token&lt;/em&gt;. A &lt;em&gt;token&lt;/em&gt; belongs to a data range, so the entire data will be divided in &lt;em&gt;tokens&lt;/em&gt;. So how is the data going to be distributed using these tokens? There are two ways: without and with virtual nodes. The main difference is that virtual nodes will use more tokens per node, (smaller ones)&lt;/p&gt;
&lt;p&gt;Other concepts were explained, like how to repair the cluster with and without virtual nodes, but at the end, the use of virtual nodes was more interesting: you can pick tokens from pretty much every node in the ring, instead of from some nodes of your entire cluster (this is due to the fact that the tokens are smaller), so if you have a lot of data to transfer because you are rebuilding a node, this can make the difference. There are other advantages, they allow heterogeneous nodes and the load balancing is simpler when adding new nodes.&lt;/p&gt;
&lt;p&gt;Another interesting part was the introduction to the &lt;strong&gt;Cassandra Query Language&lt;/strong&gt; (CQL3). Is kind of a &lt;em&gt;denormalized&lt;/em&gt; SQL, strictly real time oriented, with no joins, no sub-queries, no aggregation and a limited ORDER BY. They also announced the replace of the Thrift transport protocol for a binary (native) one, which is asynchronous, gives server notifications for new nodes and schema changes, and is totally optimized for CQL3. Another interesting concept is the request tracing, you can trace queries, for instance, seeing which node receives the query and which nodes has the requires replicas, making debugging easier for tracing anti patterns.&lt;/p&gt;
&lt;p&gt;In &lt;a href="http://berlinbuzzwords.de/sessions/cassandra-example-data-modeling-cql3"&gt;Cassandra by Example&lt;/a&gt; they extend these concepts using a Django example application called &lt;a href="https://github.com/twissandra/twissandra"&gt;Twissandra&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Scale&lt;/h1&gt;
&lt;p&gt;The most relevant talk about &lt;code&gt;scale&lt;/code&gt;, in my opinion, was &lt;a href="http://berlinbuzzwords.de/sessions/scaling-other-way-elasticsearch-miniature"&gt;Elasticsearch in Miniature&lt;/a&gt;, a nice way of presenting Elasticsearch's distributed capabilities.&lt;/p&gt;
&lt;p&gt;The cool thing is that the Elasticsearch guys installed their system in 5 Raspberry Pi, creating a test ES cluster over WiFi: this allowed them to &lt;a href="http://www.youtube.com/watch?feature=player_embedded&amp;amp;v=AA_gihv5H-Y"&gt;show us&lt;/a&gt; things like how the shards and replicas were rebalanced when the number of nodes in the cluster was changing, or what was the cluster state after destroying and creating replicas. The interesting thing is that everything went fine, having into account that this kind of demos usually tend to fail in the final presentation, and the fact that the network wasn't really reliable is a plus.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dario Blanco</dc:creator><pubDate>Tue, 30 Jul 2013 09:51:00 +0200</pubDate><guid>tag:thesoftjaguar.com,2013-07-30:posts/2013/07/30/berlin-buzzwords-2013/</guid><category>conferences</category><category>elasticsearch</category><category>solr</category><category>lucene</category><category>open-source</category><category>big-data</category><category>java</category><category>cassandra</category><category>hadoop</category><category>pig</category><category>search</category><category>store</category><category>scale</category></item><item><title>ApacheCon Europe 2012</title><link>http://thesoftjaguar.com/posts/2012/11/11/apachecon-europe-2012/</link><description>&lt;p&gt;On Wednesday it was ApacheCon day, lot of interesting stuff regarding Apache Lucene, Solr and Elasticsearch. I am not an expert with search engines, and this is a good start for establishing the basic concepts and understanding how some people have solved search problems in their systems.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Captain Obvious strikes again" src="https://pbs.twimg.com/media/A7Fb2aPCAAAtQy2.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Compound Terms Query Parser for Great Shopping Experience&lt;/h2&gt;
&lt;p&gt;This &lt;a href="http://www.apachecon.eu/schedule/presentation/18/?utm_source=twitter&amp;amp;utm_medium=social&amp;amp;utm_content=79e580ba-95ca-43cb-9739-95693cf4770e"&gt;talk&lt;/a&gt; explained the problem of returning precise search results when there are tricky queries, based on &lt;a href="http://www.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=1&amp;amp;cad=rja&amp;amp;ved=0CCcQFjAA&amp;amp;url=http%3A%2F%2Flucene.sourceforge.net%2Fpapers%2Friao97.ps&amp;amp;ei=7O-fUPHRLYSh4gTA4IGQCA&amp;amp;usg=AFQjCNF3SmHeiPe-h1A48ztdx8Qx1R-r7w"&gt;Space Optimizations for Total Ranking&lt;/a&gt; paper, and a match spotting using the info explained by the client and facet counts.&lt;/p&gt;
&lt;p&gt;However, there are some queries which are almost impossible to guess, like for example &lt;code&gt;red jeans&lt;/code&gt; in a search system which supports colors, you will have red clothes matches, matches with trademarks whose name contains &lt;code&gt;red&lt;/code&gt; or &lt;code&gt;jeans&lt;/code&gt;. You can minimize the problem, and of course the client only wants exact results, not a huge list of results that he is not going to check, but at the end a nice approach will be less guessing and more freedom to the client in his queries, for instance, specifying if he want to search by color or by trademark.&lt;/p&gt;
&lt;h2&gt;Apache Mahout in context&lt;/h2&gt;
&lt;p&gt;A nice &lt;a href="http://www.apachecon.eu/schedule/presentation/1/"&gt;explanation&lt;/a&gt; of the Apache Mahout project as a data analysis tool, and use cases of what we can do with our huge load of data.&lt;/p&gt;
&lt;p&gt;A good example of this is the &lt;code&gt;Frequently Bought Together&lt;/code&gt; and &lt;code&gt;What Other Items Do Customers Buy After Viewing This Item?&lt;/code&gt; tags in an Amazon product page.&lt;/p&gt;
&lt;h2&gt;Big Search with Big Data Principles&lt;/h2&gt;
&lt;p&gt;Eric presented his &lt;a href="http://www.apachecon.eu/schedule/presentation/13/"&gt;problem&lt;/a&gt;, which consisted in millions of text documents that should be indexed, and they could have really strange formats.&lt;/p&gt;
&lt;p&gt;The solution was nice, applying technologies in which they were familiar with, and then he spoke about &lt;code&gt;Solr4&lt;/code&gt;. We should highlight that &lt;code&gt;Solr&lt;/code&gt; is becoming a noSQL database itself (&lt;code&gt;Elasticsearch&lt;/code&gt; as well), having a key/value store engine, and they used &lt;code&gt;.avro&lt;/code&gt; files for the cache, which was quite interesting.&lt;/p&gt;
&lt;p&gt;Other design choices were &lt;code&gt;ZooKeeper&lt;/code&gt; over &lt;code&gt;NFS&lt;/code&gt;, &lt;code&gt;SCP&lt;/code&gt;, etc.. for sending files between nodes (less error prone and more obvious reasons, &lt;code&gt;ZooKeeper&lt;/code&gt; is powerful), &lt;code&gt;Apache Tika&lt;/code&gt; as a pipeline, handling the errors with an error query, &lt;code&gt;Solrmeter&lt;/code&gt; for monitoring (the central monitoring using &lt;code&gt;Nagios&lt;/code&gt; with the &lt;code&gt;Solr&lt;/code&gt; plugin), a pooled environment (like for example 1 node for development, 6 for production and the rest for load testing) and a &lt;code&gt;Grim Reaper&lt;/code&gt; for restarting instances which are not working as expected.&lt;/p&gt;
&lt;p&gt;In addition, there were some problems which are still present, like the user queries analysis, done with Solrmeter or reading them in an excel file, and the cycle scavenging, which is being done with &lt;code&gt;Condor&lt;/code&gt; but not without complications.&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hoffenheim Arena looks good at night" src="http://i.imgur.com/puR3H.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Solr 4: The SolrCloud Architecture&lt;/h2&gt;
&lt;p&gt;And it was the turn of &lt;a href="http://www.apachecon.eu/schedule/presentation/23/"&gt;showing&lt;/a&gt; how to hack a project that wasn't planned for distributed searching from the beggining, one of the biggest weaknesses in Solr.&lt;/p&gt;
&lt;p&gt;I want to highlight the use of &lt;code&gt;MurmurHash&lt;/code&gt; for assigning the documents to the different shards, &lt;code&gt;ZooKeeper&lt;/code&gt; again (in Elasticsearch this is definitely handled in a nicer way), &lt;code&gt;PeerSync&lt;/code&gt; for data replication and so on, and a last introduction to Netflix child: &lt;code&gt;Chaos Monkey&lt;/code&gt;, used for testing.&lt;/p&gt;
&lt;p&gt;SolrCloud hasn't convinced me, there are some problems when you want to scale the system, because there is a shard limit that you have to set at first, so &lt;code&gt;SolrCloud&lt;/code&gt; will assign a hash range to each shard. There are some hacks for allowing this, like the shard split (so the hash range will be reassigned). That's another problem that we have in Elasticsearch, but the shard arranging is automatic.&lt;/p&gt;
&lt;h2&gt;Personalized Search on the Largest Flash Site in America (Gilt)&lt;/h2&gt;
&lt;p&gt;Another talk regarding a &lt;a href="http://www.apachecon.eu/schedule/presentation/21/"&gt;problem&lt;/a&gt; and how a company has solved it.&lt;/p&gt;
&lt;p&gt;They were using Solr for getting only the items id (&lt;code&gt;skuId&lt;/code&gt; and &lt;code&gt;lookId&lt;/code&gt;), so Solr had only the index. Then, they enriched the search result asking the database for the rest of the params. For being able to do all of this, they created three own plugins for Solr, I didn't like this approach and in one case was a little hacky, but they know better about their own systems and at the end it was working as they expected it to work.&lt;/p&gt;
&lt;p&gt;Like with the first talk, we had the problem of the search query: the product data is not clean, it can have distractive descriptions, poorly named colors and misleading brand names. It was interesting how tricky can be the synonyms if your search engine supports this feature. At the end we have the same conclusion: maybe it is better if you leave that choice to the user for avoiding bad results.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Color names if you are a girl" src="https://pbs.twimg.com/media/A7G74L7CUAU6XLo.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Battle of the giants: Apache Solr 4.0 vs Elasticsearch&lt;/h2&gt;
&lt;p&gt;The last &lt;a href="http://www.apachecon.eu/schedule/presentation/24/"&gt;talk&lt;/a&gt; was the one in which I put more expectations, and it didn't convince me, maybe because I was hyped.&lt;/p&gt;
&lt;p&gt;It was a brief explanation of each system, which is not bad, but some query examples would have helped a lot. Elasticsearch seemed really promising with the prospective search, nested objects, moving shard and replicas, more indices storage options, index structure and not needing to reload the config. And that's what Solr doesn't have.&lt;/p&gt;
&lt;p&gt;There were also some features supported by both and well, Solr supports multilingual data handling, but is not enough. I really want to try both systems but right now, from the beginning, &lt;code&gt;Elasticsearch&lt;/code&gt; is more interesting for me, especially if I want to have a distributed search environment.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dario Blanco</dc:creator><pubDate>Sun, 11 Nov 2012 20:44:00 +0100</pubDate><guid>tag:thesoftjaguar.com,2012-11-11:posts/2012/11/11/apachecon-europe-2012/</guid><category>conferences</category><category>elasticsearch</category><category>solr</category><category>lucene</category><category>open-source</category><category>big-data</category><category>java</category></item></channel></rss>